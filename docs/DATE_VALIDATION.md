# Event-Datums-Validierung & QualitÃ¤tssicherung

## ğŸš¨ Problem: VerÃ¶ffentlichungsdatum vs. Event-Datum

### Symptome

Bei der Analyse vorhandener Events wurde festgestellt:
- **12 Events** mit Datum in der Vergangenheit (17.-18. November)
- **6 Events** am gleichen Tag (17.11.) von gleicher Quelle
- Text enthÃ¤lt "heute" aber Datum liegt 2 Tage zurÃ¼ck

**Root Cause**: Beim Scraping wurde das **VerÃ¶ffentlichungsdatum** statt des **tatsÃ¤chlichen Event-Datums** extrahiert.

## ğŸ› ï¸ LÃ¶sung: Multi-Layer-Validierung

### 1. **Validator-Script** (`scripts/validate_event_dates.py`)

PrÃ¼ft existierende Events auf hÃ¤ufige Fehler:

```bash
python3 scripts/validate_event_dates.py
```

**Erkennt:**
- âŒ Events in der Vergangenheit (sollten archiviert sein)
- âš ï¸ VerdÃ¤chtige Datums-Cluster (alle am gleichen Tag)
- ğŸ”„ Wiederkehrende Events (gleicher Titel, verschiedene Daten)
- ğŸš¨ Inkonsistente Text-Referenzen ("heute" aber altes Datum)
- ğŸ“ Dateiname-Mismatches (Dateiname â‰  Event-Datum)

**Output-Beispiel:**
```
ğŸ”´ EVENTS IN DER VERGANGENHEIT
   Anzahl: 12
   
   â€¢ Karaoke-Abend im Butler's
     Datum: 2025-11-17 (2 Tage her)
     Status: Ã–ffentlich | Quelle: Hof Programm
     
âš ï¸  VERDACHT: VERÃ–FFENTLICHUNGSDATUM STATT EVENT-DATUM
   â€¢ Datum: 2025-11-17 - 6 Events
     Quelle: Hof Programm
```

### 2. **Date Enhancer** (`scripts/editorial/date_enhancer.py`)

Hilfsklasse fÃ¼r intelligente Datumserkennung beim Scraping:

**Features:**
- **Kontext-basiertes Parsing**: Analysiert umgebenden Text
- **Konfidenz-Scoring**: 0.0-1.0 (wie sicher ist das Datum?)
- **Warnung-System**: Liste von Problemen
- **Multi-Source-Vergleich**: Kombiniert Daten aus mehreren Quellen
- **Recurring Detection**: Erkennt wiederkehrende Events

**Verwendung im Scraping:**
```python
from date_enhancer import DateEnhancer

enhancer = DateEnhancer()

# Datum mit Kontext parsen
event_date, confidence, warnings = enhancer.parse_date_with_context(
    date_text="17.11.2025",
    context_text="Heute Abend im Butler's",  # âš ï¸ "heute" erkannt!
    source_url="https://example.com/events"
)

# confidence = 0.15 (sehr niedrig!)
# warnings = ["VORSICHT: Text enthÃ¤lt 'heute' - evtl. VerÃ¶ffentlichungsdatum?"]

# Event nur erstellen wenn Konfidenz > 0.5
if confidence > 0.5:
    create_event(event_date)
else:
    log_low_confidence_event(event_date, warnings)
```

**Recurring Events erkennen:**
```python
result = enhancer.detect_recurring_pattern(
    title="Karaoke-Abend",
    description="Jeden Sonntag ab 20 Uhr"
)
# {'is_recurring': True, 'pattern': 'weekly', 'keyword': 'jeden sonntag'}
```

**Mehrere Quellen vergleichen:**
```python
sources = [
    {'source': 'Stadt Hof', 'date': date(2025, 11, 25), 'confidence': 0.8},
    {'source': 'Facebook', 'date': date(2025, 11, 25), 'confidence': 0.9},
    {'source': 'Flyer', 'date': date(2025, 11, 26), 'confidence': 0.3},
]

suggestion = enhancer.suggest_date_from_multiple_sources(sources)
# WÃ¤hlt 25.11. (2 Quellen, hÃ¶here Konfidenz)
```

### 3. **Scraping-Logging** (bereits implementiert)

Jedes Scraping erstellt detailliertes Log in `_events/_logs/`:

```log
[18:01:01] [INFO] ğŸ” Event gefunden: 'Karaoke-Abend'
[18:01:01] [INFO]    ğŸ“… Datum: 2025-11-17 | â° Zeit: 18:00
[18:01:01] [WARN] âš ï¸  Konfidenz: 0.15 (NIEDRIG)
[18:01:01] [WARN]    Warnung: Text enthÃ¤lt 'heute' - evtl. VerÃ¶ffentlichungsdatum?
[18:01:01] [INFO] ğŸ’¾ Event als ENTWURF gespeichert (manuelle PrÃ¼fung nÃ¶tig)
```

## ğŸ“‹ Best Practices fÃ¼r Scraping

### âœ… DO:

1. **Mehrere Quellen nutzen**
   ```python
   # Datum aus verschiedenen Stellen extrahieren
   date_header = extract_date_from_header()
   date_meta = extract_date_from_meta_tags()
   date_body = extract_date_from_event_description()
   
   # Vergleichen
   suggestion = enhancer.suggest_date_from_multiple_sources([...])
   ```

2. **Kontext analysieren**
   ```python
   # Nicht nur Datum parsen, sondern Kontext prÃ¼fen
   date, conf, warnings = enhancer.parse_date_with_context(
       date_text=date_str,
       context_text=full_description  # WICHTIG!
   )
   ```

3. **Konfidenz prÃ¼fen**
   ```python
   if confidence < 0.5:
       # Als Entwurf mit Warnung speichern
       event_data['status'] = 'Entwurf'
       event_data['warnings'] = warnings
   ```

4. **Wiederkehrende Events markieren**
   ```python
   recurring = enhancer.detect_recurring_pattern(title, description)
   if recurring['is_recurring']:
       event_data['recurring'] = recurring['pattern']
       event_data['recurring_note'] = f"Automatisch erkannt: {recurring['keyword']}"
   ```

5. **Validierung vor dem Speichern**
   ```python
   validation = enhancer.validate_date_consistency(event_data)
   if not validation['is_valid']:
       logger.log_error(f"Validierung fehlgeschlagen: {validation['issues']}")
   ```

### âŒ DON'T:

1. **Relative Daten blind verwenden**
   ```python
   # âŒ FALSCH
   if "heute" in text:
       event_date = datetime.now().date()  # = Scraping-Datum!
   
   # âœ… RICHTIG
   date, conf, warnings = enhancer.parse_date_with_context(date_text, context_text)
   if "heute" in warnings:
       logger.log_warning("Relatives Datum 'heute' gefunden - PrÃ¼fung nÃ¶tig")
       event_data['status'] = 'Entwurf'
   ```

2. **Erste gefundene Datum nehmen**
   ```python
   # âŒ FALSCH
   date = soup.find('time')['datetime']  # KÃ¶nnte VerÃ¶ffentlichungsdatum sein!
   
   # âœ… RICHTIG
   dates = []
   dates.append(('header', extract_from_header()))
   dates.append(('meta', extract_from_meta()))
   dates.append(('body', extract_from_body()))
   
   suggestion = enhancer.suggest_date_from_multiple_sources(dates)
   ```

3. **Ohne Validierung speichern**
   ```python
   # âŒ FALSCH
   save_event(event_data)  # Status sofort "Ã–ffentlich"
   
   # âœ… RICHTIG
   validation = enhancer.validate_date_consistency(event_data)
   if validation['confidence'] < 0.7:
       event_data['status'] = 'Entwurf'  # Manuelle PrÃ¼fung
   save_event(event_data)
   ```

## ğŸ”„ Workflow

### Automatisches Scraping

1. **Scraping lÃ¤uft** (manuell oder GitHub Actions)
2. **Date Enhancer** validiert jedes Datum
3. **Konfidenz-Check**:
   - `>= 0.7`: Event mit Status "Ã–ffentlich"
   - `0.5-0.7`: Event mit Status "Entwurf" + Warnung
   - `< 0.5`: Event Ã¼bersprungen + Logfile-Eintrag
4. **Logging**: Alle Entscheidungen in `_events/_logs/TIMESTAMP-scraping.log`

### Manuelle PrÃ¼fung

1. **Validator ausfÃ¼hren**:
   ```bash
   python3 scripts/validate_event_dates.py
   ```

2. **Report prÃ¼fen**:
   - Events in Vergangenheit â†’ Archivieren?
   - VerdÃ¤chtige Cluster â†’ Quelle nochmal checken
   - Wiederkehrende Events â†’ `recurring`-Feld hinzufÃ¼gen

3. **Admin-Bereich nutzen**: `/admin/`
   - Filter: `status:Entwurf`
   - Events mit Warnungen prÃ¼fen
   - Datum korrigieren falls nÃ¶tig
   - Status auf "Ã–ffentlich" Ã¤ndern

## ğŸ“Š Metriken

Der Validator zeigt Statistiken:
- Anzahl vergangener Events
- Anzahl verdÃ¤chtiger Cluster
- Anzahl wiederkehrender Events
- Anzahl Dateiname-Mismatches

**Ziel**: Alle Metriken bei 0!

## ğŸš€ ZukÃ¼nftige Verbesserungen

1. **AI-basierte Datumserkennung**
   - GPT-4 Vision fÃ¼r Flyer-Analyse
   - Vergleich extrahiertes Datum vs. AI-Vorschlag

2. **Cross-Reference mit offiziellen Quellen**
   - Stadt Hof Website API
   - Freiheitshalle Kalender
   - Facebook Events

3. **Automatic Fixing**
   - Bei hoher Konfidenz: Auto-Korrektur
   - Bei niedriger Konfidenz: Entwurf mit Vorschlag

4. **Recurring Events System**
   - RRULE-Format (iCalendar)
   - Automatische Instanz-Generierung
   - "NÃ¤chstes Event" Feature

## ğŸ“š Weitere Dokumentation

- `scripts/validate_event_dates.py` - Validator-Script
- `scripts/editorial/date_enhancer.py` - Date Enhancer Klasse
- `scripts/editorial/scrape_events.py` - Scraping mit Logging
- `_events/_logs/README.md` - Logging-System
