# ğŸ”„ Deduplication & Enrichment System

## Ãœberblick

Das Deduplication & Enrichment System erkennt automatisch **Duplikate** von Events, die auf **mehreren Quellen** gefunden wurden, und **merged** sie intelligent zu einem kanonischen Event mit den **besten verfÃ¼gbaren Daten**.

## Konzept

### Problem
- Events werden oft auf mehreren KanÃ¤len verÃ¶ffentlicht (Facebook, Website, Newsletter)
- Unterschiedliche Quellen haben unterschiedliche DatenqualitÃ¤t
- Manuelles ZusammenfÃ¼hren ist zeitaufwÃ¤ndig und fehleranfÃ¤llig

### LÃ¶sung
1. **Clustering**: Ã„hnliche Events werden automatisch gruppiert
2. **Confidence Scoring**: System bewertet, wie sicher es ist, dass es Duplikate sind
3. **Data Enrichment**: Beste Daten aus allen Quellen werden kombiniert
4. **Admin Review**: Redakteur entscheidet final Ã¼ber Merge

## Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     SCRAPING PHASE                          â”‚
â”‚  scrape_events.py sammelt Events von verschiedenen Quellen â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 DEDUPLICATION PHASE                         â”‚
â”‚  deduplication_engine.py erkennt Duplikate                 â”‚
â”‚  - Fuzzy-Matching (Titel, Datum, Ort)                      â”‚
â”‚  - Confidence Scoring (0.0 - 1.0)                          â”‚
â”‚  - Cluster-Bildung                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ENRICHMENT PHASE                           â”‚
â”‚  Merge der besten Daten aus allen Quellen:                â”‚
â”‚  - LÃ¤ngste Beschreibung                                    â”‚
â”‚  - Beste Bilder                                            â”‚
â”‚  - Alle Tags kombiniert                                    â”‚
â”‚  - Externe URLs gesammelt                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ADMIN REVIEW                              â”‚
â”‚  admin.html zeigt Review-Queue:                            â”‚
â”‚  - Duplikate mit niedrigem Confidence Score                â”‚
â”‚  - Links zu allen Originalquellen                          â”‚
â”‚  - Merge/Split/Ignore Aktionen                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Dateien

### Datenbanken
- **`_data/organizers.csv`**: Veranstalter-Datenbank (Namen, typische Venues, Quellen)
- **`_data/event_clusters.csv`**: Cluster-Metadaten (Duplikat-IDs, Confidence)
- **`_data/admin_review_queue.json`**: Review-Queue fÃ¼r Admin-Interface

### Scripts
- **`scripts/deduplication_engine.py`**: Hauptengine fÃ¼r Deduplication
- **`admin.html`**: Admin-Interface (Tab "ğŸ”„ Duplikate")

## Usage

### 1. Events scrapen
```bash
python3 scripts/scrape_events.py
```

### 2. Duplikate erkennen
```bash
python3 scripts/deduplication_engine.py
```

Output:
```
ğŸ” Deduplication Engine gestartet...
ğŸ“Š 3 Veranstalter geladen
ğŸ“„ 47 Event-Dateien gefunden
  â†’ 2025-12-15-weihnachtsmarkt-hof.md: Cluster cluster_1_a3f2b8c9
  â†’ 2025-12-15-xmas-market.md: Cluster cluster_1_a3f2b8c9  â† Duplikat!
  
ğŸ“Š Ergebnis: 42 Cluster gefunden
ğŸ” Veranstalter-Muster erkannt:
  Stadt Hof: 12 Events auf 3 Quellen
  
âœ… 42 Cluster gespeichert in _data/event_clusters.csv
ğŸ“ 5 Events benÃ¶tigen Review
âœ… Review-Queue gespeichert: _data/admin_review_queue.json
```

### 3. Admin Review
```bash
# Jekyll Server starten
bundle exec jekyll serve

# Browser Ã¶ffnen
http://localhost:4000/event-kalender-hof/admin.html
```

Im Admin-Interface:
1. Tab **"ğŸ”„ Duplikate"** Ã¶ffnen
2. Cluster mit niedrigem Confidence Score prÃ¼fen
3. Links zu Originalquellen Ã¶ffnen
4. Entscheidung treffen:
   - **âœ… Merge**: Duplikate zu kanonischem Event zusammenfÃ¼hren
   - **âœ‚ï¸ Split**: Nicht Duplikat, sondern unterschiedliche Events
   - **ğŸš« Ignore**: Cluster aus Queue entfernen

## Algorithmus

### Similarity-Matching

```python
def calculate_similarity(event1, event2):
    # Datum muss identisch sein
    if event1['date'] != event2['date']:
        return 0.0
    
    # Titel-Ã„hnlichkeit (60% Gewichtung)
    title_sim = SequenceMatcher(event1['title'], event2['title']).ratio()
    score = title_sim * 0.6
    
    # Location-Ã„hnlichkeit (30% Gewichtung)
    loc_sim = SequenceMatcher(event1['location'], event2['location']).ratio()
    score += loc_sim * 0.3
    
    # Zeit-Ã„hnlichkeit (10% Gewichtung, Â±30min Toleranz)
    time_diff = abs(parse_time(event1['start_time']) - parse_time(event2['start_time']))
    if time_diff <= 30:
        score += 0.1
    
    return score  # 0.0 - 1.0
```

**Threshold**: 0.8 = sehr wahrscheinlich dasselbe Event

### Confidence Scoring

```python
if len(cluster.events) >= 3:
    confidence = 0.95  # 3+ Quellen = sehr sicher
elif len(cluster.events) == 2:
    confidence = 0.75  # 2 Quellen = ziemlich sicher
else:
    confidence = 0.5   # 1 Quelle = unklar
```

### Data Quality Scoring

```python
score = 0.0
checks = [
    ('title', 10),
    ('description', 15),
    ('image', 10),
    ('external_url', 7),
    ('tags', 10),
    ...
]

for field, weight in checks:
    if event[field]:
        score += weight

quality = score / max_score  # 0.0 - 1.0
```

## Veranstalter-Muster-Erkennung

Das System lernt, welche Veranstalter typischerweise welche Quellen nutzen:

```csv
name,aliases,verified_sources,typical_venues
Stadt Hof,"Stadtverwaltung","stadt-hof,facebook-stadt-hof","Freiheitshalle,Altstadt"
```

**Nutzen**:
- Automatisches Tagging neuer Events
- PlausibilitÃ¤tschecks (Stadt Hof normalerweise nicht im Theater)
- Bessere Duplikat-Erkennung

## Admin-Interface Features

### Cluster-Karte
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ„ Weihnachtsmarkt Hof                [Hoch: 95%]  â”‚
â”‚ ğŸ“… Fr., 15. Dezember 2025 | ğŸ“ Altstadt Hof        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Duplikate gefunden: 3 Quellen                       â”‚
â”‚ Cluster ID: cluster_1_a3f2b8c9                     â”‚
â”‚ DatenqualitÃ¤t: 85% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œâ–‘                       â”‚
â”‚ Review nÃ¶tig? âœ… Nein                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ”— Gefunden auf folgenden Quellen:                  â”‚
â”‚  â€¢ Stadt Hof (2025-11-20) â†’ Quelle Ã¶ffnen â†—        â”‚
â”‚  â€¢ Facebook Stadt Hof (2025-11-19) â†’ Quelle Ã¶ffnen â†—â”‚
â”‚  â€¢ Hofer Anzeiger (2025-11-18) â†’ Quelle Ã¶ffnen â†—   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Beschreibung (merged):                              â”‚
â”‚ Der traditionelle Weihnachtsmarkt findet auch...    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [âœ… Merge] [âœ‚ï¸ Split] [ğŸš« Ignore] [ğŸ“ Details]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Farbcodierung
- **GrÃ¼n**: High Confidence (â‰¥90%) - automatisch mergen mÃ¶glich
- **Orange**: Medium Confidence (70-89%) - Review empfohlen
- **Rot**: Low Confidence (<70%) - manueller Check erforderlich

## Workflow-Integration

### Automatisierung mit GitHub Actions

```yaml
# .github/workflows/deduplication.yml
name: Event Deduplication

on:
  schedule:
    - cron: '0 2 * * *'  # TÃ¤glich 2:00 Uhr
  workflow_dispatch:

jobs:
  deduplicate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install Dependencies
        run: pip install -r requirements.txt
      
      - name: Run Deduplication
        run: python3 scripts/deduplication_engine.py
      
      - name: Commit Results
        run: |
          git config user.name "Deduplication Bot"
          git config user.email "bot@example.com"
          git add _data/event_clusters.csv _data/admin_review_queue.json
          git commit -m "chore: Update deduplication data [skip ci]"
          git push
```

## Erweiterte Features (Zukunft)

### 1. Machine Learning
- **Supervised Learning**: Aus manuellen Review-Entscheidungen lernen
- **Feature Engineering**: Bessere Similarity-Metriken

### 2. NLP-basierte Similarity
```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
embeddings1 = model.encode(event1['description'])
embeddings2 = model.encode(event2['description'])
similarity = cosine_similarity(embeddings1, embeddings2)
```

### 3. Automatisches Mergen
Bei **High Confidence** (â‰¥95%) automatisch mergen ohne Review.

### 4. Conflict Resolution
```json
{
  "conflicts": [
    {
      "field": "start_time",
      "values": ["18:00", "18:30"],
      "sources": ["Facebook", "Website"],
      "resolution": "manual"
    }
  ]
}
```

## Troubleshooting

### "Review-Queue noch nicht generiert"
```bash
python3 scripts/deduplication_engine.py
```

### "ModuleNotFoundError: No module named 'yaml'"
```bash
pip install -r requirements.txt
```

### Zu viele False Positives
- **Threshold erhÃ¶hen**: In `deduplication_engine.py` Zeile 154: `if similarity >= 0.9` (statt 0.8)
- **Strengere Zeit-Toleranz**: Zeile 141: `if time_diff <= 15` (statt 30)

### Zu wenige Duplikate erkannt
- **Threshold senken**: `if similarity >= 0.7`
- **Fuzzy-Matching verbessern**: `from fuzzywuzzy import fuzz`

## Performance

- **47 Events**: ~2 Sekunden
- **500 Events**: ~15 Sekunden
- **5000 Events**: ~3 Minuten

**Optimierung**:
```python
# Caching fÃ¼r wiederholte Normalisierungen
from functools import lru_cache

@lru_cache(maxsize=1000)
def normalize_text(text: str) -> str:
    ...
```

## Lizenz

MIT - siehe [LICENSE](../LICENSE)
