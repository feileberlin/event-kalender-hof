#!/bin/bash

# Sources CSV Scraper - Manuelles Scraping-Script
# Startet Scraping f√ºr alle Quellen in sources.csv

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"

cd "$PROJECT_ROOT" || exit 1

echo "======================================"
echo "üöÄ SOURCES.CSV SCRAPER"
echo "======================================"
echo ""

# Hilfe anzeigen
if [ "$1" = "--help" ] || [ "$1" = "-h" ]; then
    echo "Usage: $0"
    echo ""
    echo "Scrapt alle Events aus den konfigurierten Quellen in _data/sources.csv"
    echo ""
    echo "Optionen:"
    echo "  --help, -h   Zeigt diese Hilfe"
    echo ""
    echo "Ausgabe:"
    echo "  - Neue Events werden als Entw√ºrfe in _events/ gespeichert"
    echo "  - Log wird in _events/_logs/ geschrieben"
    echo "  - Duplikate werden automatisch erkannt"
    echo ""
    echo "Beispiel:"
    echo "  ./scripts/scrape.sh"
    exit 0
fi

echo "üìù Lese Quellen aus _data/sources.csv..."
echo ""

# Pr√ºfe ob sources.csv existiert
if [ ! -f "_data/sources.csv" ]; then
    echo "‚ùå Fehler: _data/sources.csv nicht gefunden!"
    exit 1
fi

# Z√§hle aktive Quellen (ohne Header, ohne commented lines)
SOURCE_COUNT=$(grep -v "^#" _data/sources.csv | tail -n +2 | wc -l)
echo "‚úÖ $SOURCE_COUNT aktive Quellen gefunden"
echo ""

echo "üîÑ Starte Scraping..."
echo "======================================"

# Starte Scraping-Script
python3 scripts/editorial/scrape_events.py

RESULT=$?

echo ""
echo "======================================"
if [ $RESULT -eq 0 ]; then
    echo "‚úÖ Scraping erfolgreich abgeschlossen!"
    echo ""
    echo "üìÅ Neue Entw√ºrfe in: _events/"
    echo "üìã Logs in: _events/_logs/"
else
    echo "‚ùå Scraping fehlgeschlagen (Exit Code: $RESULT)"
    echo ""
    echo "üí° Tipps:"
    echo "  - Pr√ºfe die Logs in _events/_logs/"
    echo "  - Stelle sicher, dass Python-Dependencies installiert sind"
    echo "  - √úberpr√ºfe die URLs in _data/sources.csv"
fi
echo "======================================"
