# Scraping Logs

Dieses Verzeichnis enthÃ¤lt detaillierte Logfiles von allen Scraping-DurchlÃ¤ufen.

## Dateiformat

`YYYYMMDD-HHMMSS-scraping.log`

Beispiel: `20251119-180101-scraping.log`

## Inhalt der Logs

Jedes Logfile dokumentiert einen kompletten Scraping-Durchlauf und enthÃ¤lt:

### 1. **Session-Start**
- Timestamp
- Anzahl geladener Venues

### 2. **Quellen-Processing**
- FÃ¼r jede gescrapte Quelle (Website, API, etc.):
  - Quellname und URL
  - Anzahl gefundener Event-Elemente
  - Parsing-Ergebnisse

### 3. **Event-Discovery**
FÃ¼r jedes gefundene Event:
- ğŸ” **Event gefunden**: Titel, Datum, Zeit, Ort
- **Hash-PrÃ¼fung**: Ist das Event neu oder ein Duplikat?
- âš ï¸ **Duplikate**: Werden mit Hash geloggt und Ã¼bersprungen

### 4. **Event-Processing**
FÃ¼r jedes neue Event:
- ğŸ›ï¸ **Venue-Enrichment**: 
  - Venue-Name aus venues.csv
  - Adresse
  - Koordinaten
  - Barrierefreiheit
- ğŸ·ï¸ **Kategorie-Ermittlung**: Automatisch aus Titel/Beschreibung
- ğŸ·ï¸ **Tag-Extraktion**: Live-Musik, Outdoor, Familie, Kostenlos, etc.

### 5. **Event-Speicherung**
- âœ… **Event-Datei erstellt**: Dateiname und Titel
- âŒ **Fehler**: Falls beim Speichern Probleme auftreten

### 6. **Session-Zusammenfassung**
- â±ï¸ Dauer des Scraping-Laufs
- ğŸ” Anzahl gefundener Events (gesamt)
- âœ… Anzahl erstellter Events
- âš ï¸ Anzahl Ã¼bersprungener Duplikate
- ğŸ›ï¸ Liste fehlender Venues (falls vorhanden)

## Verwendung

### Logs prÃ¼fen
```bash
# Neuestes Log ansehen
cat _events/_logs/$(ls -t _events/_logs/*.log | head -1)

# Alle Logs auflisten
ls -lh _events/_logs/

# Nach Fehlern suchen
grep ERROR _events/_logs/*.log

# Duplikate finden
grep "Duplikat" _events/_logs/*.log
```

### Logs bereinigen
```bash
# Alte Logs lÃ¶schen (Ã¤lter als 30 Tage)
find _events/_logs -name "*.log" -mtime +30 -delete

# Alle Logs lÃ¶schen
rm -f _events/_logs/*.log
```

## Git-Verhalten

Logfiles werden **nicht in Git committet** (.gitignore), bleiben aber lokal fÃ¼r Debugging verfÃ¼gbar.

## Automatisierung

Bei automatisierten Scraping-LÃ¤ufen (z.B. GitHub Actions) werden die Logs:
- WÃ¤hrend des Runs erstellt
- Im Workflow-Output angezeigt
- Nach Workflow-Ende verworfen (da nicht committet)

## Beispiel-Log

```log
[18:01:01] [INFO] ================================================================================
[18:01:01] [INFO] SCRAPING SESSION GESTARTET: 2025-11-19 18:01:01
[18:01:01] [INFO] ================================================================================
[18:01:01] [INFO] 
[18:01:01] [INFO] ğŸ“ Venue Manager geladen: 5 Venues
[18:01:01] [INFO] ğŸ” Starte Event-Scraping fÃ¼r Hof an der Saale...
[18:01:01] [INFO] ğŸ“… Datum: 2025-11-19 18:01:01
[18:01:01] [INFO] 
[18:01:01] [INFO] --------------------------------------------------------------------------------
[18:01:01] [INFO] ğŸ“¡ QUELLE: Stadt Hof
[18:01:01] [INFO] ğŸ”— URL: https://www.hof.de/events
[18:01:01] [INFO] --------------------------------------------------------------------------------
[18:01:01] [INFO] ğŸ“„ HTML geparst: 12 Event-Elemente gefunden
[18:01:01] [INFO] ğŸ” Event gefunden: 'Weihnachtsmarkt 2025'
[18:01:01] [INFO]    ğŸ“… Datum: 2025-12-15 | â° Zeit: 14:00
[18:01:01] [INFO]    ğŸ“ Ort: Altstadt Hof
[18:01:01] [INFO] ğŸ›ï¸  Venue gefunden fÃ¼r 'Altstadt Hof':
[18:01:01] [INFO]    âœ“ Kanonischer Name: Altstadt Hof
[18:01:01] [INFO]    âœ“ Adresse: Altstadt, 95028 Hof
[18:01:01] [INFO]    âœ“ Koordinaten: 50.3200, 11.9180
[18:01:01] [INFO] ğŸ·ï¸  Kategorie ermittelt: 'Kultur' (aus Titel: 'Weihnachtsmarkt 2025')
[18:01:01] [INFO] âœ… Event-Datei erstellt: 2025-12-15-weihnachtsmarkt-2025.md
[18:01:01] [INFO]    ğŸ“ Titel: 'Weihnachtsmarkt 2025'
```

## Support

Bei Fragen zum Logging-System siehe `docs/SCRAPING.md` oder `scripts/scrape_events.py`.
